{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21638122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina os caminhos\n",
    "SOURCE_DATA_DIR = \"C:/Mestrado/Materias/pesquisa/tomates/tomatotest/processed_data\"\n",
    "TARGET_DATA_DIR = \"C:/Mestrado/Materias/pesquisa/tomates/tomatotest/processed_data_256\" # Nova pasta\n",
    "TARGET_SIZE = (256, 256)\n",
    "\n",
    "# print(f\"Criando nova estrutura de pastas em: {TARGET_DATA_DIR}\")\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"train/images\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"train/masks\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"validation/images\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"validation/masks\"), exist_ok=True)\n",
    "\n",
    "# def process_single_image(args):\n",
    "#     filename, source_img_folder, source_mask_folder, target_img_folder, target_mask_folder = args\n",
    "#     try:\n",
    "#         with Image.open(os.path.join(source_img_folder, filename)) as img:\n",
    "#             img_resized = img.resize(TARGET_SIZE, Image.LANCZOS)\n",
    "#             img_resized.save(os.path.join(target_img_folder, filename))\n",
    "\n",
    "#         mask_filename = filename.replace(\".jpg\", \".png\")\n",
    "#         mask_path = os.path.join(source_mask_folder, mask_filename)\n",
    "#         if not os.path.exists(mask_path):\n",
    "#             mask_path = os.path.join(source_mask_folder, filename) # Tenta o mesmo nome\n",
    "\n",
    "#         with Image.open(mask_path) as mask:\n",
    "#             mask_resized = mask.resize(TARGET_SIZE, Image.NEAREST)\n",
    "#             mask_resized.save(os.path.join(target_mask_folder, mask_filename))\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro ao processar {filename}: {e}\")\n",
    "\n",
    "# def preprocess_dataset(subset):\n",
    "#     print(f\"\\nProcessando o conjunto de dados: {subset}\")\n",
    "#     source_img_folder = os.path.join(SOURCE_DATA_DIR, f\"{subset}/images\")\n",
    "#     source_mask_folder = os.path.join(SOURCE_DATA_DIR, f\"{subset}/masks\")\n",
    "#     target_img_folder = os.path.join(TARGET_DATA_DIR, f\"{subset}/images\")\n",
    "#     target_mask_folder = os.path.join(TARGET_DATA_DIR, f\"{subset}/masks\")\n",
    "#     image_files = os.listdir(source_img_folder)\n",
    "\n",
    "#     args_list = [\n",
    "#         (filename, source_img_folder, source_mask_folder, target_img_folder, target_mask_folder)\n",
    "#         for filename in image_files\n",
    "#     ]\n",
    "\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "#         list(tqdm(executor.map(process_single_image, args_list), total=len(args_list), desc=f\"Redimensionando {subset} images\"))\n",
    "\n",
    "# # Executar para treino e validação\n",
    "# preprocess_dataset(\"train\")\n",
    "# preprocess_dataset(\"validation\")\n",
    "\n",
    "# print(\"\\nPré-processamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee303b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURAÇÃO E HIPERPARÂMETROS ---\n",
    "# Sinta-se à vontade para parametrizar e testar diferentes valores\n",
    "\n",
    "# 1. Configurações do Ambiente e Caminhos\n",
    "# CONFIRME SE ESTE CAMINHO ESTÁ CORRETO!\n",
    "# DATA_DIR = \"C:/Mestrado/Materias/pesquisa/tomates/tomatotest/processed_data\"\n",
    "DATA_DIR = \"C:/Mestrado/Materias/pesquisa/tomates/tomatotest/processed_data_256\"\n",
    "MODEL_SAVE_PATH = \"./tomato_unet_best.pth\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando o dispositivo: {DEVICE}\")\n",
    "\n",
    "# 2. Hiperparâmetros do Modelo e Treinamento\n",
    "# a) Analise os hiperparâmetros usados\n",
    "#    - LEARNING_RATE: Taxa de aprendizado. Controla o tamanho do passo na otimização.\n",
    "#      Valores comuns: 1e-3, 1e-4, 1e-5.\n",
    "#    - BATCH_SIZE: Número de imagens por lote. Depende da memória da sua GPU.\n",
    "#      Valores comuns: 4, 8, 16, 32.\n",
    "#    - NUM_EPOCHS: Número de vezes que o modelo verá todo o dataset de treino.\n",
    "#    - OPTIMIZER: Algoritmo de otimização. 'Adam' é um padrão robusto. 'SGD' com momentum\n",
    "#      também é uma opção clássica.\n",
    "#    - LOSS_FUNCTION: Como medimos o erro. 'BCEWithLogitsLoss' é padrão para\n",
    "#      classificação binária. 'DiceLoss' é excelente para segmentação e lida\n",
    "#      bem com desbalanceamento de classes. Uma combinação dos dois é ainda melhor.\n",
    "\n",
    "config = {\n",
    "    \"LEARNING_RATE\": 1e-4,\n",
    "    \"BATCH_SIZE\": 4,\n",
    "    \"NUM_EPOCHS\": 50,\n",
    "    \"IMAGE_HEIGHT\": 256, # Redimensionar imagens para um tamanho fixo\n",
    "    \"IMAGE_WIDTH\": 256,\n",
    "    \"OPTIMIZER\": \"Adam\", # Opções: \"Adam\", \"SGD\"\n",
    "    \"LOSS_FUNCTION\": \"DiceBCE\" # Opções: \"BCE\", \"Dice\", \"DiceBCE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Pré-processamento, análise estatística dos dados, visualização\n",
    "\n",
    "# Vamos visualizar algumas imagens e máscaras para entender os dados\n",
    "train_img_dir = os.path.join(DATA_DIR, \"train/images\")\n",
    "train_mask_dir = os.path.join(DATA_DIR, \"train/masks\")\n",
    "\n",
    "# Pegar uma lista de imagens (assumindo que os nomes correspondem)\n",
    "sample_images = os.listdir(train_img_dir)[:3]\n",
    "\n",
    "fig, axs = plt.subplots(len(sample_images), 2, figsize=(8, 12))\n",
    "fig.suptitle('Amostras de Imagens e Máscaras de Treino')\n",
    "\n",
    "for i, img_name in enumerate(sample_images):\n",
    "    img_path = os.path.join(train_img_dir, img_name)\n",
    "    # Assumindo que a máscara tem o mesmo nome, mas talvez extensão diferente\n",
    "    # Tente .png ou .jpg se necessário\n",
    "    mask_path = os.path.join(train_mask_dir, img_name.replace('.jpg', '.png'))\n",
    "    if not os.path.exists(mask_path):\n",
    "        mask_path = os.path.join(train_mask_dir, img_name)\n",
    "\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\") # Converter para tons de cinza\n",
    "\n",
    "    axs[i, 0].imshow(image)\n",
    "    axs[i, 0].set_title(f\"Imagem: {img_name}\")\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    axs[i, 1].imshow(mask, cmap='gray')\n",
    "    axs[i, 1].set_title(f\"Máscara: {os.path.basename(mask_path)}\")\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análise Estatística Simples: Proporção de pixels de tomate\n",
    "print(\"Analisando a proporção de pixels de 'tomate' nas máscaras de treino...\")\n",
    "mask_files = os.listdir(train_mask_dir)\n",
    "tomato_proportions = []\n",
    "for mask_file in tqdm(mask_files[:100]): # Analisar as primeiras 100 para ser rápido\n",
    "    mask_path = os.path.join(train_mask_dir, mask_file)\n",
    "    mask_np = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "    proportion = np.sum(mask_np > 128) / (mask_np.shape[0] * mask_np.shape[1])\n",
    "    if proportion > 0: # Apenas se houver tomate\n",
    "        tomato_proportions.append(proportion)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(tomato_proportions, bins=30, color='crimson')\n",
    "plt.title('Histograma da Proporção de Pixels de Tomate por Máscara')\n",
    "plt.xlabel('Proporção de Área do Tomate na Imagem')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n",
    "print(f\"Análise concluída. Média da proporção (em imagens com tomates): {np.mean(tomato_proportions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f690dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe customizada para carregar os dados\n",
    "class TomatoDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.images[index]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "\n",
    "        # Tratar extensões diferentes entre imagem e máscara\n",
    "        mask_name = img_name\n",
    "        possible_mask_exts = ['.png', '.jpg', '.jpeg']\n",
    "        for ext in possible_mask_exts:\n",
    "            if mask_name.endswith(ext):\n",
    "                base_name = mask_name[:-len(ext)]\n",
    "                break\n",
    "        else:\n",
    "            base_name = mask_name\n",
    "\n",
    "        mask_path = None\n",
    "        for ext in possible_mask_exts:\n",
    "            potential_path = os.path.join(self.mask_dir, base_name + ext)\n",
    "            if os.path.exists(potential_path):\n",
    "                mask_path = potential_path\n",
    "                break\n",
    "\n",
    "        if mask_path is None:\n",
    "            # Tenta com o mesmo nome exato se falhar\n",
    "             mask_path = os.path.join(self.mask_dir, img_name)\n",
    "             if not os.path.exists(mask_path):\n",
    "                raise FileNotFoundError(f\"Não foi possível encontrar a máscara para a imagem {img_name}\")\n",
    "\n",
    "\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
    "\n",
    "        # Normalizar máscara para 0.0-1.0\n",
    "        mask[mask == 255.0] = 1.0\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Definir transformações (redimensionamento e conversão para tensor)\n",
    "# Para data augmentation, pode-se usar a biblioteca Albumentations\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Por simplicidade, usaremos torchvision transforms\n",
    "NUM_WORKERS = 0 # <<<< COMECE COM ESTE VALOR\n",
    "\n",
    "# --- Transformações ---\n",
    "# Como você já pré-processou, não precisamos mais do Resize\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "class CustomTomatoDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, img_transform, mask_transform):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_transform = img_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "        # Pega a lista de imagens e cria uma referência para as máscaras\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        \n",
    "        # Verificação inicial: Checa se pelo menos a primeira máscara existe\n",
    "        if len(self.image_files) > 0:\n",
    "            self._verify_path(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def _verify_path(self, index):\n",
    "        \"\"\"Função interna para encontrar o caminho correto da máscara.\"\"\"\n",
    "        img_name = self.image_files[index]\n",
    "        base_name, _ = os.path.splitext(img_name)\n",
    "        \n",
    "        # Tenta as extensões mais comuns para máscaras\n",
    "        possible_mask_names = [f\"{base_name}.png\", f\"{base_name}.jpg\", f\"{base_name}.jpeg\"]\n",
    "        \n",
    "        for mask_name in possible_mask_names:\n",
    "            mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                return mask_path\n",
    "        \n",
    "        # Se não encontrar, levanta um erro claro\n",
    "        raise FileNotFoundError(f\"Não foi possível encontrar a máscara para a imagem '{img_name}'. \"\n",
    "                              f\"Procurado por {possible_mask_names} na pasta {self.mask_dir}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            # Caminho da imagem\n",
    "            img_path = os.path.join(self.image_dir, self.image_files[index])\n",
    "            \n",
    "            # Caminho da máscara (verificado pela função interna)\n",
    "            mask_path = self._verify_path(index)\n",
    "            \n",
    "            # Carregar imagem e máscara\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "            # Aplicar transformações\n",
    "            image = self.img_transform(image)\n",
    "            mask = self.mask_transform(mask)\n",
    "            \n",
    "            # Binarizar a máscara para garantir 0s e 1s\n",
    "            mask = (mask > 0.5).float()\n",
    "            \n",
    "            return image, mask\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar o item no índice {index}, arquivo: {self.image_files[index]}\")\n",
    "            # Retornar o erro para que o DataLoader possa lidar com ele (ou pular o item)\n",
    "            raise e\n",
    "\n",
    "\n",
    "# Criar Datasets\n",
    "try:\n",
    "    # ATENÇÃO: Verifique se o DATA_DIR está apontando para a pasta pré-processada (ex: .../processed_data_256)\n",
    "    train_ds = CustomTomatoDataset(\n",
    "        image_dir=os.path.join(DATA_DIR, \"train/images\"),\n",
    "        mask_dir=os.path.join(DATA_DIR, \"train/masks\"),\n",
    "        img_transform=data_transform,\n",
    "        mask_transform=mask_transform\n",
    "    )\n",
    "\n",
    "    val_ds = CustomTomatoDataset(\n",
    "        image_dir=os.path.join(DATA_DIR, \"validation/images\"),\n",
    "        mask_dir=os.path.join(DATA_DIR, \"validation/masks\"),\n",
    "        img_transform=data_transform,\n",
    "        mask_transform=mask_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=config[\"BATCH_SIZE\"],\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=config[\"BATCH_SIZE\"],\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset de treino: {len(train_ds)} amostras.\")\n",
    "    print(f\"Dataset de validação: {len(val_ds)} amostras.\")\n",
    "    print(f\"DataLoader usando {NUM_WORKERS} workers.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao criar os datasets: {e}\")\n",
    "\n",
    "print(f\"Dataset de treino: {len(train_ds)} amostras.\")\n",
    "print(f\"Dataset de validação: {len(val_ds)} amostras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb79aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco de convolução dupla usado na U-Net\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Implementação da U-Net\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Encoder (Down path)\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Decoder (Up path)\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = transforms.functional.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Teste rápido para ver se a arquitetura está correta\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "x = torch.randn(2, 3, config[\"IMAGE_HEIGHT\"], config[\"IMAGE_WIDTH\"]).to(DEVICE)\n",
    "preds = model(x)\n",
    "assert preds.shape == (2, 1, config[\"IMAGE_HEIGHT\"], config[\"IMAGE_WIDTH\"])\n",
    "print(\"Arquitetura U-Net carregada com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica 1: Dice Coefficient / F1 Score\n",
    "# Essencial para artigos de segmentação\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs) # Aplicar sigmoid para ter probabilidades\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "# Métrica 2: Intersection over Union (IoU) / Jaccard Index\n",
    "# Também essencial\n",
    "def check_accuracy_and_get_metrics(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    iou_score = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).unsqueeze(1) if len(y.shape) == 3 else y.to(device)\n",
    "\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "\n",
    "            # Calcular Dice e IoU por lote e somar\n",
    "            intersection = (preds * y).sum()\n",
    "            union = (preds + y).sum() - intersection\n",
    "            dice_score += (2. * intersection) / ((preds + y).sum() + 1e-8)\n",
    "            iou_score += intersection / (union + 1e-8)\n",
    "\n",
    "\n",
    "    accuracy = num_correct/num_pixels*100\n",
    "    avg_dice = dice_score/len(loader)\n",
    "    avg_iou = iou_score/len(loader)\n",
    "\n",
    "    print(f\"Acurácia de pixels: {accuracy:.2f}%\")\n",
    "    print(f\"Dice Score (Média): {avg_dice:.4f}\")\n",
    "    print(f\"IoU/Jaccard (Média): {avg_iou:.4f}\")\n",
    "\n",
    "    model.train()\n",
    "    return avg_iou, avg_dice\n",
    "\n",
    "# Escolher a função de perda com base na configuração\n",
    "if config[\"LOSS_FUNCTION\"] == \"BCE\":\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "elif config[\"LOSS_FUNCTION\"] == \"Dice\":\n",
    "    loss_fn = DiceLoss()\n",
    "elif config[\"LOSS_FUNCTION\"] == \"DiceBCE\":\n",
    "    class DiceBCELoss(nn.Module):\n",
    "        def __init__(self, weight=None, size_average=True):\n",
    "            super(DiceBCELoss, self).__init__()\n",
    "        def forward(self, inputs, targets, smooth=1):\n",
    "            inputs_sig = torch.sigmoid(inputs)\n",
    "            inputs_flat = inputs_sig.view(-1)\n",
    "            targets_flat = targets.view(-1)\n",
    "            intersection = (inputs_flat * targets_flat).sum()\n",
    "            dice_loss = 1 - (2. * intersection + smooth) / (inputs_flat.sum() + targets_flat.sum() + smooth)\n",
    "            bce = nn.BCEWithLogitsLoss()(inputs, targets)\n",
    "            return bce + dice_loss\n",
    "    loss_fn = DiceBCELoss()\n",
    "\n",
    "# Escolher o otimizador\n",
    "if config[\"OPTIMIZER\"] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "elif config[\"OPTIMIZER\"] == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config[\"LEARNING_RATE\"], momentum=0.9)\n",
    "\n",
    "print(f\"Otimizador: {config['OPTIMIZER']}, Função de Perda: {config['LOSS_FUNCTION']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78781614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o loop de uma época\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        # Adicionar dimensão de canal para a máscara\n",
    "        targets = targets.float().to(device=DEVICE)\n",
    "\n",
    "        # Forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update tqdm loop\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# --- INÍCIO DO TREINAMENTO ---\n",
    "history = {'train_loss': [], 'val_iou': [], 'val_dice': []}\n",
    "best_val_iou = -1.0\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(\"\\n--- Iniciando o Treinamento ---\")\n",
    "for epoch in range(config[\"NUM_EPOCHS\"]):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "    history['train_loss'].append(train_loss)\n",
    "\n",
    "    # Checar acurácia e métricas na validação\n",
    "    print(f\"\\n--- ÉPOCA {epoch+1}/{config['NUM_EPOCHS']} ---\")\n",
    "    print(f\"Loss de Treino: {train_loss:.4f}\")\n",
    "    print(\"Métricas de Validação:\")\n",
    "    val_iou, val_dice = check_accuracy_and_get_metrics(val_loader, model, device=DEVICE)\n",
    "    history['val_iou'].append(val_iou.item())\n",
    "    history['val_dice'].append(val_dice.item())\n",
    "\n",
    "    # Salvar o melhor modelo\n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"** Novo melhor IoU: {best_val_iou:.4f}. Modelo salvo em {MODEL_SAVE_PATH} **\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    print(f\"Duração da Época: {epoch_duration:.2f} segundos\")\n",
    "\n",
    "print(\"--- Treinamento Concluído ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar gráficos de treinamento para o artigo\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfico de Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.title(\"Loss de Treinamento por Época\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico de Métricas de Validação\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_iou'], label='Validation IoU', color='orange')\n",
    "plt.plot(history['val_dice'], label='Validation Dice', color='purple')\n",
    "plt.title(\"Métricas de Validação por Época\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizar predições no conjunto de validação\n",
    "print(\"\\n--- Visualizando Predições ---\")\n",
    "\n",
    "# Carregar o melhor modelo salvo\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Pegar algumas imagens de validação\n",
    "num_samples_to_show = 3\n",
    "val_images, val_masks = next(iter(val_loader))\n",
    "\n",
    "fig, axs = plt.subplots(num_samples_to_show, 3, figsize=(15, 15))\n",
    "fig.suptitle('Resultados: Imagem Original vs. Máscara Real vs. Predição do Modelo', fontsize=16)\n",
    "\n",
    "\n",
    "# Desnormalizar imagem para visualização\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "for i in range(num_samples_to_show):\n",
    "    image = val_images[i].to(DEVICE)\n",
    "    true_mask = val_masks[i].squeeze().cpu().numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_mask = model(image.unsqueeze(0))\n",
    "        pred_mask = torch.sigmoid(pred_mask)\n",
    "        pred_mask = (pred_mask > 0.5).float().squeeze().cpu().numpy()\n",
    "\n",
    "    image_display = inv_normalize(image).cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Imagem Original\n",
    "    axs[i, 0].imshow(image_display)\n",
    "    axs[i, 0].set_title(\"Imagem Original\")\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    # Máscara Real (Ground Truth)\n",
    "    axs[i, 1].imshow(true_mask, cmap='gray')\n",
    "    axs[i, 1].set_title(\"Máscara Real\")\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    # Predição do Modelo\n",
    "    axs[i, 2].imshow(pred_mask, cmap='gray')\n",
    "    axs[i, 2].set_title(\"Predição do Modelo\")\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
