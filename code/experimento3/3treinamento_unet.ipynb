{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b98535",
   "metadata": {},
   "source": [
    "### **Resumo do Experimento #3: U-Net com Data Augmentation**\n",
    "\n",
    "* **Objetivo:** Avaliar o impacto de Data Augmentation na performance e robustez do modelo, mantendo a base de hiperparâmetros do experimento anterior.\n",
    "\n",
    "* **Arquitetura do Modelo:**\n",
    "    * U-Net\n",
    "\n",
    "* **Configuração do Treinamento:**\n",
    "    * **Função de Perda:** Dice + BCE Loss (`DiceBCELoss`)\n",
    "    * **Otimizador:** Adam\n",
    "    * **Taxa de Aprendizado Inicial:** `1e-4`\n",
    "    * **Batch Size:** `4`\n",
    "    * **Número Máximo de Épocas:** `75`\n",
    "\n",
    "* **Agendador de Taxa de Aprendizado (Scheduler):**\n",
    "    * **Estratégia:** `ReduceLROnPlateau`\n",
    "    * **Métrica Monitorada:** `Validation IoU`\n",
    "    * **Paciência:** `5` épocas\n",
    "    * **Fator de Redução:** `0.2`\n",
    "\n",
    "* **Data Augmentation (aplicada apenas no treino):**\n",
    "    * Resize para `256x256`\n",
    "    * Rotação Aleatória (limite de 35 graus)\n",
    "    * Flip Horizontal Aleatório\n",
    "    * Flip Vertical Aleatório\n",
    "    * Variação de Cor Aleatória (brilho, contraste, saturação, matiz)\n",
    "    * Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 1\n",
    "# Importar as bibliotecas necessárias\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import concurrent.futures\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21638122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 2\n",
    "# Defina os caminhos\n",
    "SOURCE_DATA_DIR = \"C:/Mestrado/Materias/pesquisa/tomates/tomatotest/processed_data\"\n",
    "TARGET_DATA_DIR = \"C:/Mestrado/Materias/pesquisa/tomates/tomatotest/processed_data_256\" # Nova pasta\n",
    "TARGET_SIZE = (256, 256)\n",
    "\n",
    "# print(f\"Criando nova estrutura de pastas em: {TARGET_DATA_DIR}\")\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"train/images\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"train/masks\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"validation/images\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(TARGET_DATA_DIR, \"validation/masks\"), exist_ok=True)\n",
    "\n",
    "# def process_single_image(args):\n",
    "#     filename, source_img_folder, source_mask_folder, target_img_folder, target_mask_folder = args\n",
    "#     try:\n",
    "#         with Image.open(os.path.join(source_img_folder, filename)) as img:\n",
    "#             img_resized = img.resize(TARGET_SIZE, Image.LANCZOS)\n",
    "#             img_resized.save(os.path.join(target_img_folder, filename))\n",
    "\n",
    "#         mask_filename = filename.replace(\".jpg\", \".png\")\n",
    "#         mask_path = os.path.join(source_mask_folder, mask_filename)\n",
    "#         if not os.path.exists(mask_path):\n",
    "#             mask_path = os.path.join(source_mask_folder, filename) # Tenta o mesmo nome\n",
    "\n",
    "#         with Image.open(mask_path) as mask:\n",
    "#             mask_resized = mask.resize(TARGET_SIZE, Image.NEAREST)\n",
    "#             mask_resized.save(os.path.join(target_mask_folder, mask_filename))\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro ao processar {filename}: {e}\")\n",
    "\n",
    "# def preprocess_dataset(subset):\n",
    "#     print(f\"\\nProcessando o conjunto de dados: {subset}\")\n",
    "#     source_img_folder = os.path.join(SOURCE_DATA_DIR, f\"{subset}/images\")\n",
    "#     source_mask_folder = os.path.join(SOURCE_DATA_DIR, f\"{subset}/masks\")\n",
    "#     target_img_folder = os.path.join(TARGET_DATA_DIR, f\"{subset}/images\")\n",
    "#     target_mask_folder = os.path.join(TARGET_DATA_DIR, f\"{subset}/masks\")\n",
    "#     image_files = os.listdir(source_img_folder)\n",
    "\n",
    "#     args_list = [\n",
    "#         (filename, source_img_folder, source_mask_folder, target_img_folder, target_mask_folder)\n",
    "#         for filename in image_files\n",
    "#     ]\n",
    "\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "#         list(tqdm(executor.map(process_single_image, args_list), total=len(args_list), desc=f\"Redimensionando {subset} images\"))\n",
    "\n",
    "# # Executar para treino e validação\n",
    "# preprocess_dataset(\"train\")\n",
    "# preprocess_dataset(\"validation\")\n",
    "\n",
    "# print(\"\\nPré-processamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee303b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 3\n",
    "# --- Configurações do Ambiente e Caminhos ---\n",
    "# Certifique-se de que este caminho aponta para os dados pré-processados\n",
    "DATA_DIR = \"C:/Mestrado/Materias/pesquisa/tomates/tomatotest/processed_data_256\" \n",
    "MODEL_SAVE_PATH = \"./tomato_unet_best.pth\"  # O modelo será salvo com este nome\n",
    "CSV_LOG_PATH = \"./training_log.csv\"      # O log será salvo aqui\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando o dispositivo: {DEVICE}\")\n",
    "\n",
    "# --- Hiperparâmetros para o Treinamento v2 ---\n",
    "config = {\n",
    "    \"LEARNING_RATE\": 1e-4,       # LR inicial. O scheduler vai ajustá-lo.\n",
    "    \"BATCH_SIZE\": 4,\n",
    "    \"NUM_EPOCHS\": 75,            # Aumentamos para dar mais tempo para o modelo aprender.\n",
    "    \"IMAGE_HEIGHT\": 256,\n",
    "    \"IMAGE_WIDTH\": 256,\n",
    "    \"OPTIMIZER\": \"Adam\",\n",
    "    \"LOSS_FUNCTION\": \"DiceBCE\"\n",
    "}\n",
    "\n",
    "# NOVO: Configuração do Agendador de Taxa de Aprendizado (Scheduler)\n",
    "scheduler_config = {\n",
    "    \"factor\": 0.2,               # Fator de redução do LR (new_lr = lr * factor). 0.1 ou 0.2 são comuns.\n",
    "    \"patience\": 5,               # Nº de épocas sem melhora no val_iou para reduzir o LR.\n",
    "    \"min_lr\": 1e-7,              # Taxa de aprendizado mínima.\n",
    "    \"verbose\": True              # Imprime uma mensagem quando o LR é atualizado.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 4\n",
    "# a) Pré-processamento, análise estatística dos dados, visualização\n",
    "\n",
    "# Vamos visualizar algumas imagens e máscaras para entender os dados\n",
    "train_img_dir = os.path.join(DATA_DIR, \"train/images\")\n",
    "train_mask_dir = os.path.join(DATA_DIR, \"train/masks\")\n",
    "\n",
    "# Pegar uma lista de imagens (assumindo que os nomes correspondem)\n",
    "sample_images = os.listdir(train_img_dir)[:3]\n",
    "\n",
    "fig, axs = plt.subplots(len(sample_images), 2, figsize=(8, 12))\n",
    "fig.suptitle('Amostras de Imagens e Máscaras de Treino')\n",
    "\n",
    "for i, img_name in enumerate(sample_images):\n",
    "    img_path = os.path.join(train_img_dir, img_name)\n",
    "    # Assumindo que a máscara tem o mesmo nome, mas talvez extensão diferente\n",
    "    # Tente .png ou .jpg se necessário\n",
    "    mask_path = os.path.join(train_mask_dir, img_name.replace('.jpg', '.png'))\n",
    "    if not os.path.exists(mask_path):\n",
    "        mask_path = os.path.join(train_mask_dir, img_name)\n",
    "\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\") # Converter para tons de cinza\n",
    "\n",
    "    axs[i, 0].imshow(image)\n",
    "    axs[i, 0].set_title(f\"Imagem: {img_name}\")\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    axs[i, 1].imshow(mask, cmap='gray')\n",
    "    axs[i, 1].set_title(f\"Máscara: {os.path.basename(mask_path)}\")\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análise Estatística Simples: Proporção de pixels de tomate\n",
    "print(\"Analisando a proporção de pixels de 'tomate' nas máscaras de treino...\")\n",
    "mask_files = os.listdir(train_mask_dir)\n",
    "tomato_proportions = []\n",
    "for mask_file in tqdm(mask_files[:100]): # Analisar as primeiras 100 para ser rápido\n",
    "    mask_path = os.path.join(train_mask_dir, mask_file)\n",
    "    mask_np = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "    proportion = np.sum(mask_np > 128) / (mask_np.shape[0] * mask_np.shape[1])\n",
    "    if proportion > 0: # Apenas se houver tomate\n",
    "        tomato_proportions.append(proportion)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(tomato_proportions, bins=30, color='crimson')\n",
    "plt.title('Histograma da Proporção de Pixels de Tomate por Máscara')\n",
    "plt.xlabel('Proporção de Área do Tomate na Imagem')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n",
    "print(f\"Análise concluída. Média da proporção (em imagens com tomates): {np.mean(tomato_proportions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f690dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 5\n",
    "# Classe customizada para carregar os dados\n",
    "class TomatoDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.images[index]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        # Assumindo que a máscara é .png e a imagem é .jpg\n",
    "        mask_path = os.path.join(self.mask_dir, img_name.replace(\".jpg\", \".png\"))\n",
    "        if not os.path.exists(mask_path):\n",
    "             mask_path = os.path.join(self.mask_dir, img_name) # Tenta o mesmo nome se falhar\n",
    "\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "        mask[mask == 255.0] = 1.0 # Garante que a máscara seja 0 ou 1\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "# --- DEFINIÇÃO DAS TRANSFORMAÇÕES ---\n",
    "# Novas transformações de treino com Data Augmentation\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=config[\"IMAGE_HEIGHT\"], width=config[\"IMAGE_WIDTH\"]),\n",
    "        A.Rotate(limit=35, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ColorJitter(p=0.5, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Transformações de validação (sem augmentation, apenas resize e normalização)\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=config[\"IMAGE_HEIGHT\"], width=config[\"IMAGE_WIDTH\"]),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Definir transformações (redimensionamento e conversão para tensor)\n",
    "# Para data augmentation, pode-se usar a biblioteca Albumentations\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Por simplicidade, usaremos torchvision transforms\n",
    "NUM_WORKERS = 0 # <<<< COMECE COM ESTE VALOR\n",
    "\n",
    "# --- Transformações ---\n",
    "# Como você já pré-processou, não precisamos mais do Resize\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "class CustomTomatoDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, img_transform, mask_transform):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_transform = img_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "        # Pega a lista de imagens e cria uma referência para as máscaras\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        \n",
    "        # Verificação inicial: Checa se pelo menos a primeira máscara existe\n",
    "        if len(self.image_files) > 0:\n",
    "            self._verify_path(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def _verify_path(self, index):\n",
    "        \"\"\"Função interna para encontrar o caminho correto da máscara.\"\"\"\n",
    "        img_name = self.image_files[index]\n",
    "        base_name, _ = os.path.splitext(img_name)\n",
    "        \n",
    "        # Tenta as extensões mais comuns para máscaras\n",
    "        possible_mask_names = [f\"{base_name}.png\", f\"{base_name}.jpg\", f\"{base_name}.jpeg\"]\n",
    "        \n",
    "        for mask_name in possible_mask_names:\n",
    "            mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                return mask_path\n",
    "        \n",
    "        # Se não encontrar, levanta um erro claro\n",
    "        raise FileNotFoundError(f\"Não foi possível encontrar a máscara para a imagem '{img_name}'. \"\n",
    "                              f\"Procurado por {possible_mask_names} na pasta {self.mask_dir}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            # Caminho da imagem\n",
    "            img_path = os.path.join(self.image_dir, self.image_files[index])\n",
    "            \n",
    "            # Caminho da máscara (verificado pela função interna)\n",
    "            mask_path = self._verify_path(index)\n",
    "            \n",
    "            # Carregar imagem e máscara\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "            # Aplicar transformações\n",
    "            image = self.img_transform(image)\n",
    "            mask = self.mask_transform(mask)\n",
    "            \n",
    "            # Binarizar a máscara para garantir 0s e 1s\n",
    "            mask = (mask > 0.5).float()\n",
    "            \n",
    "            return image, mask\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar o item no índice {index}, arquivo: {self.image_files[index]}\")\n",
    "            # Retornar o erro para que o DataLoader possa lidar com ele (ou pular o item)\n",
    "            raise e\n",
    "\n",
    "\n",
    "# Criar Datasets\n",
    "try:\n",
    "    # ATENÇÃO: Verifique se o DATA_DIR está apontando para a pasta pré-processada (ex: .../processed_data_256)\n",
    "    print(\"Criando Datasets com Data Augmentation...\")\n",
    "    train_ds = CustomTomatoDataset(\n",
    "        image_dir=os.path.join(DATA_DIR, \"train/images\"),\n",
    "        mask_dir=os.path.join(DATA_DIR, \"train/masks\"),\n",
    "        transform=train_transforms\n",
    "    )\n",
    "\n",
    "    val_ds = CustomTomatoDataset(\n",
    "        image_dir=os.path.join(DATA_DIR, \"validation/images\"),\n",
    "        mask_dir=os.path.join(DATA_DIR, \"validation/masks\"),\n",
    "        transform=val_transforms\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=config[\"BATCH_SIZE\"],\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=config[\"BATCH_SIZE\"],\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset de treino com augmentation: {len(train_ds)} amostras.\")\n",
    "    print(f\"Dataset de validação: {len(val_ds)} amostras.\")\n",
    "    print(f\"DataLoader usando {NUM_WORKERS} workers.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao criar os datasets: {e}\")\n",
    "\n",
    "print(f\"Dataset de treino: {len(train_ds)} amostras.\")\n",
    "print(f\"Dataset de validação: {len(val_ds)} amostras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb79aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 6\n",
    "# Bloco de convolução dupla usado na U-Net\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Implementação da U-Net\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Encoder (Down path)\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Decoder (Up path)\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = transforms.functional.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Teste rápido para ver se a arquitetura está correta\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "x = torch.randn(2, 3, config[\"IMAGE_HEIGHT\"], config[\"IMAGE_WIDTH\"]).to(DEVICE)\n",
    "preds = model(x)\n",
    "assert preds.shape == (2, 1, config[\"IMAGE_HEIGHT\"], config[\"IMAGE_WIDTH\"])\n",
    "print(\"Arquitetura U-Net carregada com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 7\n",
    "# Métrica 1: Dice Coefficient / F1 Score\n",
    "# Essencial para artigos de segmentação\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs) # Aplicar sigmoid para ter probabilidades\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "# Métrica 2: Intersection over Union (IoU) / Jaccard Index\n",
    "# Também essencial\n",
    "def check_accuracy_and_get_metrics(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    iou_score = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).unsqueeze(1) if len(y.shape) == 3 else y.to(device)\n",
    "\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "\n",
    "            # Calcular Dice e IoU por lote e somar\n",
    "            intersection = (preds * y).sum()\n",
    "            union = (preds + y).sum() - intersection\n",
    "            dice_score += (2. * intersection) / ((preds + y).sum() + 1e-8)\n",
    "            iou_score += intersection / (union + 1e-8)\n",
    "\n",
    "\n",
    "    accuracy = num_correct/num_pixels*100\n",
    "    avg_dice = dice_score/len(loader)\n",
    "    avg_iou = iou_score/len(loader)\n",
    "\n",
    "    print(f\"Acurácia de pixels: {accuracy:.2f}%\")\n",
    "    print(f\"Dice Score (Média): {avg_dice:.4f}\")\n",
    "    print(f\"IoU/Jaccard (Média): {avg_iou:.4f}\")\n",
    "\n",
    "    model.train()\n",
    "    return avg_iou, avg_dice\n",
    "\n",
    "# Escolher a função de perda com base na configuração\n",
    "if config[\"LOSS_FUNCTION\"] == \"BCE\":\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "elif config[\"LOSS_FUNCTION\"] == \"Dice\":\n",
    "    loss_fn = DiceLoss()\n",
    "elif config[\"LOSS_FUNCTION\"] == \"DiceBCE\":\n",
    "    class DiceBCELoss(nn.Module):\n",
    "        def __init__(self, weight=None, size_average=True):\n",
    "            super(DiceBCELoss, self).__init__()\n",
    "        def forward(self, inputs, targets, smooth=1):\n",
    "            inputs_sig = torch.sigmoid(inputs)\n",
    "            inputs_flat = inputs_sig.view(-1)\n",
    "            targets_flat = targets.view(-1)\n",
    "            intersection = (inputs_flat * targets_flat).sum()\n",
    "            dice_loss = 1 - (2. * intersection + smooth) / (inputs_flat.sum() + targets_flat.sum() + smooth)\n",
    "            bce = nn.BCEWithLogitsLoss()(inputs, targets)\n",
    "            return bce + dice_loss\n",
    "    loss_fn = DiceBCELoss()\n",
    "\n",
    "# Escolher o otimizador\n",
    "if config[\"OPTIMIZER\"] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "elif config[\"OPTIMIZER\"] == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config[\"LEARNING_RATE\"], momentum=0.9)\n",
    "\n",
    "print(f\"Otimizador: {config['OPTIMIZER']}, Função de Perda: {config['LOSS_FUNCTION']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78781614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELULA 8\n",
    "# Função para o loop de uma época\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        # Adicionar dimensão de canal para a máscara\n",
    "        targets = targets.float().to(device=DEVICE)\n",
    "\n",
    "        # Forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update tqdm loop\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# --- INÍCIO DO TREINAMENTO ---\n",
    "history = {'train_loss': [], 'val_iou': [], 'val_dice': []}\n",
    "best_val_iou = -1.0\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "loss_fn = DiceBCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Instancia o Agendador de Taxa de Aprendizado\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    'max', # Queremos maximizar o IoU\n",
    "    factor=scheduler_config[\"factor\"],\n",
    "    patience=scheduler_config[\"patience\"],\n",
    "    min_lr=scheduler_config[\"min_lr\"],\n",
    "    verbose=scheduler_config[\"verbose\"]\n",
    ")\n",
    "\n",
    "# --- INICIALIZAÇÃO DO LOG ---\n",
    "best_val_iou = -1.0\n",
    "\n",
    "# Cria o arquivo CSV e escreve o cabeçalho\n",
    "with open(CSV_LOG_PATH, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # MUDANÇA 1: Adicionada a coluna 'duration_sec' ao cabeçalho\n",
    "    writer.writerow(['epoch', 'train_loss', 'val_iou', 'val_dice', 'learning_rate', 'duration_sec'])\n",
    "print(f\"Arquivo de log criado em: {CSV_LOG_PATH}\")\n",
    "\n",
    "# --- LOOP DE TREINAMENTO ---\n",
    "print(\"\\n--- Iniciando o Treinamento Final ---\")\n",
    "for epoch in range(config[\"NUM_EPOCHS\"]):\n",
    "    start_time = time.time()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "    model.eval()\n",
    "    val_iou, val_dice = check_accuracy_and_get_metrics(val_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Calcula a duração da época ANTES de imprimir, para poder salvar no log\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    \n",
    "    # Imprime o resumo da época\n",
    "    print(f\"\\n--- ÉPOCA {epoch+1}/{config['NUM_EPOCHS']} ---\")\n",
    "    print(f\"Loss de Treino: {train_loss:.4f} | LR: {current_lr:.2e}\")\n",
    "    print(f\"Validação -> IoU: {val_iou:.4f} | Dice: {val_dice:.4f}\")\n",
    "    print(f\"Duração da Época: {epoch_duration:.2f} segundos\")\n",
    "\n",
    "    scheduler.step(val_iou)\n",
    "\n",
    "    # Salva os dados da época no arquivo CSV\n",
    "    with open(CSV_LOG_PATH, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # MUDANÇA 2: Adicionada a variável epoch_duration à linha salva\n",
    "        writer.writerow([epoch+1, train_loss, val_iou.item(), val_dice.item(), current_lr, epoch_duration])\n",
    "\n",
    "    # Salva o melhor modelo\n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"** Novo melhor IoU: {best_val_iou:.4f}. Modelo salvo! **\")\n",
    "\n",
    "print(\"--- Treinamento Concluído ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CÉLULA 11: ANÁLISE FINAL, GRÁFICOS E MÉTRICAS (SUBSTITUIR)\n",
    "# ===================================================================\n",
    "\n",
    "# --- 1. CARREGAR DADOS E O MELHOR MODELO ---\n",
    "print(f\"Carregando o melhor modelo salvo de '{MODEL_SAVE_PATH}'...\")\n",
    "# Recria a arquitetura do modelo para carregar os pesos\n",
    "analysis_model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "analysis_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "analysis_model.eval() # Coloca o modelo em modo de avaliação definitivo\n",
    "\n",
    "print(f\"Carregando log de treinamento de '{CSV_LOG_PATH}'...\")\n",
    "log_df = pd.read_csv(CSV_LOG_PATH)\n",
    "\n",
    "\n",
    "# --- 2. GERAR GRÁFICOS DE TREINAMENTO ---\n",
    "print(\"Gerando gráficos de treinamento...\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 18))\n",
    "fig.suptitle('Análise Completa do Treinamento', fontsize=18)\n",
    "\n",
    "# Gráfico 1: Loss de Treino\n",
    "sns.lineplot(x='epoch', y='train_loss', data=log_df, ax=ax1, color='blue', label='Train Loss')\n",
    "ax1.set_title('Loss de Treinamento por Época')\n",
    "ax1.set_xlabel('Época')\n",
    "ax1.set_ylabel('Dice+BCE Loss')\n",
    "\n",
    "# Gráfico 2: Métricas de Validação\n",
    "sns.lineplot(x='epoch', y='val_iou', data=log_df, ax=ax2, color='green', label='Validation IoU')\n",
    "sns.lineplot(x='epoch', y='val_dice', data=log_df, ax=ax2, color='red', label='Validation Dice/F1')\n",
    "ax2.set_title('Métricas de Validação por Época')\n",
    "ax2.set_xlabel('Época')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.legend()\n",
    "\n",
    "# Gráfico 3: Taxa de Aprendizado\n",
    "sns.lineplot(x='epoch', y='learning_rate', data=log_df, ax=ax3, color='purple', label='Learning Rate')\n",
    "ax3.set_title('Taxa de Aprendizado por Época')\n",
    "ax3.set_xlabel('Época')\n",
    "ax3.set_ylabel('Learning Rate')\n",
    "ax3.set_yscale('log') # Escala logarítmica para ver melhor as quedas\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 3. CÁLCULO DE MÉTRICAS FINAIS DETALHADAS ---\n",
    "def calculate_final_metrics(loader, model, device):\n",
    "    print(\"\\nCalculando métricas finais detalhadas no conjunto de validação...\")\n",
    "    dice_scores, iou_scores, precisions, recalls = [], [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Calculando Métricas Finais\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            if len(y.shape) == 3: y = y.unsqueeze(1)\n",
    "            \n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "            \n",
    "            tp = (preds * y).sum()\n",
    "            fp = ((1 - y) * preds).sum()\n",
    "            fn = (y * (1 - preds)).sum()\n",
    "            \n",
    "            precision = (tp + 1e-6) / (tp + fp + 1e-6)\n",
    "            recall = (tp + 1e-6) / (tp + fn + 1e-6)\n",
    "            dice = (2 * tp + 1e-6) / (2 * tp + fp + fn + 1e-6)\n",
    "            iou = (tp + 1e-6) / (tp + fp + fn + 1e-6)\n",
    "            \n",
    "            precisions.append(precision.item())\n",
    "            recalls.append(recall.item())\n",
    "            dice_scores.append(dice.item())\n",
    "            iou_scores.append(iou.item())\n",
    "\n",
    "    final_metrics = {\n",
    "        \"IoU\": np.mean(iou_scores),\n",
    "        \"Dice/F1\": np.mean(dice_scores),\n",
    "        \"Precision\": np.mean(precisions),\n",
    "        \"Recall\": np.mean(recalls)\n",
    "    }\n",
    "    return final_metrics\n",
    "\n",
    "final_metrics = calculate_final_metrics(val_loader, analysis_model, DEVICE)\n",
    "\n",
    "\n",
    "# --- 4. EXIBIR TABELA DE RESULTADOS FINAIS ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"      RESULTADOS FINAIS DO MELHOR MODELO\")\n",
    "print(\"=\"*40)\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric:<12}: {value:.4f}\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- 5. VISUALIZAÇÃO QUALITATIVA DAS PREDIÇÕES ---\n",
    "print(\"Gerando visualizações de predições do melhor modelo...\")\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "val_images, val_masks = next(iter(val_loader))\n",
    "num_images = min(5, len(val_images))\n",
    "\n",
    "fig, axs = plt.subplots(num_images, 3, figsize=(15, num_images * 5))\n",
    "fig.suptitle('Resultados Visuais: Imagem Original vs. Máscara Real vs. Predição', fontsize=16)\n",
    "\n",
    "for i in range(num_images):\n",
    "    image_tensor = val_images[i].to(DEVICE)\n",
    "    true_mask_np = val_masks[i].squeeze().cpu().numpy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_mask = analysis_model(image_tensor.unsqueeze(0))\n",
    "        pred_mask = torch.sigmoid(pred_mask)\n",
    "        pred_mask_np = (pred_mask > 0.5).float().squeeze().cpu().numpy()\n",
    "\n",
    "    image_display = inv_normalize(image_tensor).cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "    axs[i, 0].imshow(np.clip(image_display, 0, 1))\n",
    "    axs[i, 0].set_title(f\"Imagem de Exemplo {i+1}\")\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    axs[i, 1].imshow(true_mask_np, cmap='gray')\n",
    "    axs[i, 1].set_title(\"Máscara Real (Ground Truth)\")\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    axs[i, 2].imshow(pred_mask_np, cmap='gray')\n",
    "    axs[i, 2].set_title(\"Predição do Modelo\")\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
