# AnÃ¡lise Comparativa de Arquiteturas de Deep Learning para SegmentaÃ§Ã£o SemÃ¢ntica de Tomates

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o e anÃ¡lise comparativa de trÃªs arquiteturas de redes neurais convolucionais (CNNs) para segmentaÃ§Ã£o semÃ¢ntica de frutos de tomate em imagens de campo.

## ğŸ¯ Objetivo

O objetivo principal Ã© determinar qual arquitetura de deep learning Ã© mais eficaz para a tarefa de segmentaÃ§Ã£o semÃ¢ntica de tomates em condiÃ§Ãµes reais de campo, contribuindo para o avanÃ§o da agricultura de precisÃ£o atravÃ©s da fenotipagem automatizada.

## ğŸ“Š Dataset Utilizado

### 1. Escolha do Dataset
- **Dataset**: `tomatotest` - Dataset pÃºblico disponibilizado por He et al. (2024)
- **Fonte**: Coletado no Mountain Horticultural Crops Research and Extension Center, NC, EUA
- **DisponÃ­vel em**: [https://huggingface.co/datasets/XingjianLi/tomatotest](https://huggingface.co/datasets/XingjianLi/tomatotest)
- **CaracterÃ­sticas**:
  - 21.367 imagens capturadas em ambiente real de campo
  - ResoluÃ§Ã£o original: 2448 Ã— 2048 pixels
  - Capturadas com robÃ´ terrestre autÃ´nomo (HuskyBot) equipado com sistema de cÃ¢mera estÃ©reo
  - CondiÃ§Ãµes desafiadoras: iluminaÃ§Ã£o variÃ¡vel, oclusÃ£o por folhas, fundos complexos

### 2. Justificativa da Escolha
O dataset foi escolhido por:
- **Complexidade adequada**: Imagens reais de campo com condiÃ§Ãµes desafiadoras
- **RelevÃ¢ncia para pesquisa**: AplicaÃ§Ã£o direta em agricultura de precisÃ£o
- **Qualidade dos dados**: AnotaÃ§Ãµes precisas e dataset bem estruturado
- **Escala apropriada**: Quantidade significativa de dados para treinamento robusto

## ğŸ” AnÃ¡lise ExploratÃ³ria de Dados

### PrÃ©-processamento Realizado
1. **ConversÃ£o de Formato**: ExtraÃ§Ã£o de arquivos HDF5 (.h5) para PNG
2. **GeraÃ§Ã£o de MÃ¡scaras**: CriaÃ§Ã£o de mÃ¡scaras binÃ¡rias de segmentaÃ§Ã£o
3. **Redimensionamento**: Imagens redimensionadas para 256Ã—256 pixels
4. **AugmentaÃ§Ã£o de Dados**: AplicaÃ§Ã£o de espelhamento horizontal

### AnÃ¡lise EstatÃ­stica
- **ProporÃ§Ã£o de Pixels de Tomate**: MÃ©dia de 0,57% por imagem
- **Desbalanceamento de Classes**: Identificado forte desbalanceamento (muitos pixels de fundo vs. poucos pixels de tomate)
- **DistribuiÃ§Ã£o dos Dados**: 80% para treinamento, 20% para validaÃ§Ã£o

### VisualizaÃ§Ãµes Implementadas
- Histograma da proporÃ§Ã£o de pixels de tomate por mÃ¡scara
- GrÃ¡ficos de evoluÃ§Ã£o das mÃ©tricas de validaÃ§Ã£o por Ã©poca
- Curvas de perda durante o treinamento
- Exemplos qualitativos de prediÃ§Ãµes do modelo

## ğŸ¤– TÃ©cnicas de Aprendizado de MÃ¡quina

### TÃ©cnica Aplicada: SegmentaÃ§Ã£o SemÃ¢ntica (Deep Learning)

#### Justificativa da Escolha
A **segmentaÃ§Ã£o semÃ¢ntica** foi escolhida porque:
- **PrecisÃ£o na localizaÃ§Ã£o**: NecessÃ¡ria para delimitar exatamente os contornos dos tomates
- **AplicaÃ§Ã£o prÃ¡tica**: Essencial para contagem precisa de frutos e estimativa de produÃ§Ã£o
- **Vantagem sobre outras tÃ©cnicas**: 
  - ClassificaÃ§Ã£o de imagens: Muito simples (um rÃ³tulo por imagem)
  - DetecÃ§Ã£o de objetos: Apenas caixas delimitadoras, sem contornos precisos
  - SegmentaÃ§Ã£o semÃ¢ntica: ClassificaÃ§Ã£o pixel a pixel, permitindo mediÃ§Ãµes precisas

### Algoritmos Implementados

#### 1. U-Net
- **Arquitetura**: Encoder-decoder com skip connections
- **Vantagens**: Preserva detalhes espaciais de alta resoluÃ§Ã£o
- **AplicaÃ§Ã£o**: Ideal para localizaÃ§Ã£o precisa de objetos pequenos
- **Resultado**: **Melhor performance** - IoU: 0.8265, Dice/F1: 0.9033

#### 2. DeepLabV3
- **Arquitetura**: ConvoluÃ§Ãµes atrÃ³ficas com mÃ³dulo ASPP
- **Vantagens**: AnÃ¡lise multi-escala sem perda de resoluÃ§Ã£o
- **AplicaÃ§Ã£o**: Robusto para objetos de tamanhos variados
- **Resultado**: IoU: 0.5793, Dice/F1: 0.7309

#### 3. PSPNet (Pyramid Scene Parsing Network)
- **Arquitetura**: MÃ³dulo de pyramid pooling para contexto global
- **Vantagens**: CompreensÃ£o da estrutura geral da cena
- **AplicaÃ§Ã£o**: Ideal para parsing de cenas complexas
- **Resultado**: IoU: 0.5528, Dice/F1: 0.7120

### HiperparÃ¢metros Utilizados

| ParÃ¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| Ã‰pocas | 100 | ConvergÃªncia adequada observada |
| Otimizador | Adam | Eficiente e amplamente usado |
| FunÃ§Ã£o de Perda | Dice Loss + BCE | Combate desbalanceamento de classes |
| ResoluÃ§Ã£o | 256Ã—256 | Compromisso entre detalhes e viabilidade computacional |
| AugmentaÃ§Ã£o | Espelhamento horizontal | Duplica dataset e melhora generalizaÃ§Ã£o |

### MÃ©tricas de AvaliaÃ§Ã£o
- **IoU (Intersection over Union)**: MÃ©trica mais rigorosa para segmentaÃ§Ã£o
- **Dice Coefficient (F1-Score)**: Medida de sobreposiÃ§Ã£o, mais flexÃ­vel que IoU
- **PrecisÃ£o**: AcurÃ¡cia das prediÃ§Ãµes positivas
- **Recall**: Completude das prediÃ§Ãµes positivas

## ğŸ“ˆ Resultados Principais

### Performance Quantitativa
| Modelo | IoU | Dice/F1 | PrecisÃ£o | Recall |
|--------|-----|---------|----------|--------|
| **U-Net** | **0.8265** | **0.9033** | **0.9487** | **0.8630** |
| DeepLabV3 | 0.5793 | 0.7309 | 0.7516 | 0.7140 |
| PSPNet | 0.5528 | 0.7120 | 0.7351 | 0.6903 |

### Principais Descobertas
1. **Superioridade da U-Net**: 42-50% melhor que as outras arquiteturas
2. **ImportÃ¢ncia dos Skip Connections**: PreservaÃ§Ã£o de detalhes espaciais Ã© crucial
3. **EficÃ¡cia da Abordagem Supervisionada**: Aprendizado direto supera mÃ©todos mais complexos para esta tarefa especÃ­fica

## ğŸ—‚ï¸ Estrutura do RepositÃ³rio

```
â”œâ”€â”€ README.md                              # Este arquivo
â”œâ”€â”€ code/                                  # CÃ³digo fonte
â”‚   â”œâ”€â”€ experimento1/                      # Experimentos U-Net
â”‚   â”œâ”€â”€ experimento2/                      # Experimentos U-Net (variaÃ§Ãµes)
â”‚   â”œâ”€â”€ experimento3/                      # Experimentos U-Net (variaÃ§Ãµes)
â”‚   â”œâ”€â”€ experimento4/                      # Experimentos U-Net (variaÃ§Ãµes)
â”‚   â”œâ”€â”€ experimento5/                      # Experimentos DeepLabV3
â”‚   â”œâ”€â”€ experimento6/                      # Experimentos PSPNet
â”‚   â”œâ”€â”€ data_augmentation_tomates.ipynb    # AnÃ¡lise e augmentaÃ§Ã£o de dados
â”‚   â””â”€â”€ redimensionar imagens para 256.py # PrÃ©-processamento
â”œâ”€â”€ tomatotest/                            # Dataset e scripts
â”‚   â”œâ”€â”€ data/                              # Dados brutos
â”‚   â”œâ”€â”€ processed_data/                    # Dados processados
â”‚   â””â”€â”€ processed_data_256/                # Dados redimensionados
â””â”€â”€ ARTIGO BASE - Highâ€Throughput Robotic... # Artigo de referÃªncia
```

## ğŸš€ Como Executar

### PrÃ©-requisitos
```bash
pip install torch torchvision opencv-python matplotlib numpy pandas
```

### ExecuÃ§Ã£o dos Experimentos
1. **PrÃ©-processamento**: Execute `redimensionar imagens para 256.py`
2. **AnÃ¡lise ExploratÃ³ria**: Abra `data_augmentation_tomates.ipynb`
3. **Treinamento U-Net**: Execute notebooks em `experimento1/` a `experimento4/`
4. **Treinamento DeepLabV3**: Execute notebook em `experimento5/`
5. **Treinamento PSPNet**: Execute notebook em `experimento6/`

## ğŸ“Š AnÃ¡lise dos Resultados

### Por que a U-Net foi Superior?
1. **Alinhamento Arquitetural**: Skip connections ideais para localizaÃ§Ã£o precisa
2. **PreservaÃ§Ã£o de Detalhes**: MantÃ©m informaÃ§Ãµes espaciais de alta resoluÃ§Ã£o
3. **AdequaÃ§Ã£o Ã  Tarefa**: Tomates sÃ£o objetos pequenos que requerem delimitaÃ§Ã£o precisa
4. **CaracterÃ­sticas Locais**: Mais importantes que contexto global nesta aplicaÃ§Ã£o

### LimitaÃ§Ãµes e Trabalhos Futuros
- Explorar tÃ©cnicas de augmentaÃ§Ã£o mais sofisticadas
- Testar backbones mais modernos (ResNet, EfficientNet)
- OtimizaÃ§Ã£o sistemÃ¡tica de hiperparÃ¢metros
- ValidaÃ§Ã£o em outros datasets agrÃ­colas

## ğŸ† CrÃ©ditos e ReferÃªncias

### Dataset
Este projeto utiliza o dataset `tomatotest` criado e disponibilizado por:
- **Autores**: Weilong He, Xingjian Li, Zhenghua Zhang, Yuxi Chen, Jianbo Zhang, Dilip R. Panthee, Inga Meadows, Lirong Xiang
- **DisponÃ­vel em**: [https://huggingface.co/datasets/XingjianLi/tomatotest](https://huggingface.co/datasets/XingjianLi/tomatotest)

### Artigo Base
O trabalho Ã© baseado no artigo cientÃ­fico:
**"High-Throughput Robotic Phenotyping for Quantifying Tomato Disease Severity Enabled by Synthetic Data and Domain-Adaptive Semantic Segmentation"**

**Autores**: 
- Weilong HeÂ¹'Â²
- Xingjian LiÂ²'Â³ 
- Zhenghua ZhangÂ¹'Â²
- Yuxi ChenÂ³
- Jianbo Zhangâ´
- Dilip R. Panthee
- Inga Meadows
- Lirong XiangÂ¹'Â²

## ğŸ‘¥ ContribuiÃ§Ãµes

Este projeto foi desenvolvido como parte da pesquisa de mestrado em CiÃªncia da ComputaÃ§Ã£o na Universidade Federal de UberlÃ¢ndia, sob orientaÃ§Ã£o acadÃªmica especÃ­fica para a disciplina de MineraÃ§Ã£o de Dados.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a Apache-2.0 - veja o arquivo LICENSE para detalhes.

---

**Contato**: henriquemoreiraa@gmail.com  
**InstituiÃ§Ã£o**: Universidade Federal de UberlÃ¢ndia  
**Programa**: Mestrado em CiÃªncia da ComputaÃ§Ã£o